{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit0c1bca6249c346019beab994c59ed139",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "source": [
    "Training Images Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 3502 images belonging to 10 classes.\n"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "idg_train=ImageDataGenerator(rescale=1./250,\n",
    "                              zoom_range=0.2,\n",
    "                              shear_range=0.2)\n",
    "try:\n",
    "    train_data=idg_train.flow_from_directory(\n",
    "                                  'images/train',\n",
    "                                   target_size=(64,64),\n",
    "                                   batch_size=32,\n",
    "                                   class_mode='categorical')\n",
    "except:IOError                                   "
   ]
  },
  {
   "source": [
    "Testing Images(Validation_set) Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 568 images belonging to 10 classes.\n"
    }
   ],
   "source": [
    "idg_test=ImageDataGenerator(rescale=1./250)\n",
    "try:\n",
    "    test_data=idg_test.flow_from_directory('images/test',\n",
    "                                   target_size=(64,64),\n",
    "                                   batch_size=32,\n",
    "                                   class_mode='categorical')\n",
    "except:IOError                                   "
   ]
  },
  {
   "source": [
    "Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout,BatchNormalization,GlobalAveragePooling2D\n",
    "\n",
    "cnn=Sequential()\n",
    "\n",
    "cnn.add(Conv2D(filters=128,kernel_size=5,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(MaxPool2D(pool_size=3,strides=1))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=3,strides=1))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=3,strides=1))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=3,strides=1))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=3,strides=1))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(GlobalAveragePooling2D(data_format='channels_last'))\n",
    "cnn.add(Dense(units=10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_29 (Conv2D)           (None, 60, 60, 128)       9728      \n_________________________________________________________________\nmax_pooling2d_29 (MaxPooling (None, 58, 58, 128)       0         \n_________________________________________________________________\ndropout_35 (Dropout)         (None, 58, 58, 128)       0         \n_________________________________________________________________\nbatch_normalization_29 (Batc (None, 58, 58, 128)       512       \n_________________________________________________________________\nconv2d_30 (Conv2D)           (None, 56, 56, 64)        73792     \n_________________________________________________________________\nmax_pooling2d_30 (MaxPooling (None, 54, 54, 64)        0         \n_________________________________________________________________\ndropout_36 (Dropout)         (None, 54, 54, 64)        0         \n_________________________________________________________________\nbatch_normalization_30 (Batc (None, 54, 54, 64)        256       \n_________________________________________________________________\nconv2d_31 (Conv2D)           (None, 52, 52, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_31 (MaxPooling (None, 50, 50, 32)        0         \n_________________________________________________________________\ndropout_37 (Dropout)         (None, 50, 50, 32)        0         \n_________________________________________________________________\nbatch_normalization_31 (Batc (None, 50, 50, 32)        128       \n_________________________________________________________________\nconv2d_32 (Conv2D)           (None, 48, 48, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_32 (MaxPooling (None, 46, 46, 32)        0         \n_________________________________________________________________\ndropout_38 (Dropout)         (None, 46, 46, 32)        0         \n_________________________________________________________________\nbatch_normalization_32 (Batc (None, 46, 46, 32)        128       \n_________________________________________________________________\nconv2d_33 (Conv2D)           (None, 44, 44, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_33 (MaxPooling (None, 42, 42, 32)        0         \n_________________________________________________________________\ndropout_39 (Dropout)         (None, 42, 42, 32)        0         \n_________________________________________________________________\nbatch_normalization_33 (Batc (None, 42, 42, 32)        128       \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 32)                0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 10)                330       \n=================================================================\nTotal params: 121,962\nTrainable params: 121,386\nNon-trainable params: 576\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt=Adam(learning_rate=1e-2)\n",
    "\n",
    "cnn.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n110/110 [==============================] - 221s 2s/step - loss: 2.0061 - acc: 0.2944 - val_loss: 3.7601 - val_acc: 0.1655\nEpoch 2/10\n110/110 [==============================] - 226s 2s/step - loss: 1.9066 - acc: 0.3192 - val_loss: 4.5742 - val_acc: 0.1215\nEpoch 3/10\n110/110 [==============================] - 227s 2s/step - loss: 1.8476 - acc: 0.3475 - val_loss: 7.2740 - val_acc: 0.0933\nEpoch 4/10\n110/110 [==============================] - 225s 2s/step - loss: 1.7707 - acc: 0.3955 - val_loss: 3.4533 - val_acc: 0.1426\nEpoch 5/10\n110/110 [==============================] - 225s 2s/step - loss: 1.7375 - acc: 0.3943 - val_loss: 2.4528 - val_acc: 0.2588\nEpoch 6/10\n110/110 [==============================] - 225s 2s/step - loss: 1.7225 - acc: 0.4066 - val_loss: 2.9593 - val_acc: 0.1373\nEpoch 7/10\n110/110 [==============================] - 225s 2s/step - loss: 1.6830 - acc: 0.4246 - val_loss: 3.0788 - val_acc: 0.2236\nEpoch 8/10\n110/110 [==============================] - 224s 2s/step - loss: 1.6507 - acc: 0.4306 - val_loss: 2.7768 - val_acc: 0.2218\nEpoch 9/10\n110/110 [==============================] - 225s 2s/step - loss: 1.6483 - acc: 0.4412 - val_loss: 2.1677 - val_acc: 0.2641\nEpoch 10/10\n110/110 [==============================] - 224s 2s/step - loss: 1.6027 - acc: 0.4509 - val_loss: 2.3216 - val_acc: 0.2676\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f5644c84290>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "\n",
    "\n",
    "    cnn.fit(x=train_data,validation_data=test_data,epochs=10)\n"
   ]
  }
 ]
}